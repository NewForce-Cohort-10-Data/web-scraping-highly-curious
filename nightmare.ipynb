{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5af5710-7e2b-46b7-9dc8-9bed6f6cf906",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3a3b8ea2-b8e9-419f-b141-89d43dd93a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', \"Kid Rock's Comedy Jam\", 'Nateland Presents', 'Nikki Glaser', 'Jim Jefferies', 'Jay Leno', 'Wanda Sykes', 'Titan of Twang: A Celebration of Duane Eddy', 'CeCe Winans', 'Amos Lee', 'Ryman Sidewalk Sessions with Onoleigh', 'Sammy Rae & The Friends', 'Stonebridge Bible Church: Easter at the Ryman']\n"
     ]
    }
   ],
   "source": [
    " # Start by using either the inspector or by viewing the page source. Can you identify a tag that might be helpful for finding the names of all performers? For now, just worry about the headliner and don't worry about the opener.\n",
    "\n",
    "url = 'https://ryman.com/events/'\n",
    "response = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "headliners = []\n",
    "\n",
    "event_items = soup.find_all('div', class_='eventItem')\n",
    "\n",
    "for event in event_items:\n",
    "    headliner = event.find('h3', class_='title')\n",
    "    if headliner:\n",
    "        headliners.append(headliner.get_text(strip=True))\n",
    "\n",
    "print(headliners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2dade766-02f6-481d-8f6e-c33c6c0ffd3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dates: ['Apr 7,  2025', 'Apr 8,  2025', 'Apr 9,  2025', 'Apr 11,  2025', 'Apr 12,  2025', 'Apr 13,  2025', 'Apr 13,  2025', 'Apr 14,  2025', 'Apr 16,  2025', 'Apr 17,  2025', 'Apr 19,  2025']\n",
      "Times: ['7:00 PM', '7:00 PM', 'TBD', '7:00 PM', '7:30 PM', '7:00 PM', '7:30 PM', '7:30 PM', 'TBD', '5:30 PM', '8:00 PM']\n"
     ]
    }
   ],
   "source": [
    "dates = []\n",
    "times = []\n",
    "\n",
    "for event in event_items:\n",
    "    date_div = event.find('div', class_='date')\n",
    "    \n",
    "    if date_div:\n",
    "        month_tag = date_div.find('span', class_='m-date__month')\n",
    "        day_tag = date_div.find('span', class_='m-date__day')\n",
    "        year_tag = date_div.find('span', class_='m-date__year')\n",
    "        time_tag = date_div.find('span', class_='m-date__hour')\n",
    "        \n",
    "        # Extract text safely\n",
    "        month = month_tag.get_text(strip=True) if month_tag else ''\n",
    "        day = day_tag.get_text(strip=True) if day_tag else ''\n",
    "        year = year_tag.get_text(strip=True).replace(',', '') if year_tag else ''\n",
    "        time_str = time_tag.get_text(strip=True) if time_tag else 'TBD'  # Handle missing times\n",
    "        \n",
    "        if month and day and year:  # Only append complete dates\n",
    "            dates.append(f\"{month} {day}, {year}\")\n",
    "            times.append(time_str)\n",
    "\n",
    "# Debugging output\n",
    "print(\"Dates:\", dates)\n",
    "print(\"Times:\", times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d436ae83-2a6e-49d0-ba37-4afb08d2001e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 11 11\n"
     ]
    }
   ],
   "source": [
    "print(len(headliners), len(dates), len(times))\n",
    "\n",
    "# events_df = pd.DataFrame({\n",
    "#     'Headliner': headliners,\n",
    "#     'Date': dates,\n",
    "#     'Time': times\n",
    "# })\n",
    "# print(events_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05fce27-8609-4497-86de-6ea311e25dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. **Bonus #2:**: Now, let's see if we can get the results beyond the first page. For this, you'll need to Web Developer Tools of your browser and navigate to the Network tab. Click the \"Load More Events\" button and you should see a GET request to the www.ryman.com domain.  \n",
    "#     a. Inspect this request and you should see that it goes to a URL like \"https://www.ryman.com/events/events_ajax/24?category=0&venue=0&team=0&exclude=&per_page=12&came_from_page=event-list-page\". In your Jupyter notebook, send a get request to this url and inspect the results.  \n",
    "#     b. You should find that the results that you get are HTML, but that they are not exactly formatted in a way that can be parsed. See if you can clean up the results set so that you can extract out the same information as above.  \n",
    "#     c. Create a DataFrame that contains data for the next 60 shows."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
